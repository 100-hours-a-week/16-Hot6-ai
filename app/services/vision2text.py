# fastapi_project/app/services/vision2text.py
import httpx, json
from ..core.config import get_settings
from transformers import Blip2Processor, Blip2ForConditionalGeneration
import torch
import openai
from PIL import Image
from dotenv import load_dotenv

settings = get_settings()

class Img2Txt:
    def __init__(self, image_path: str):
        # image_path: S3ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ ê²½ë¡œ
        load_dotenv()
        self.image_path = image_path
        self.processor = Blip2Processor.from_pretrained(settings.BLIP2_MODEL)
        self.model = Blip2ForConditionalGeneration.from_pretrained(settings.BLIP2_MODEL, torch_dtype=torch.float16).to("cuda" if torch.cuda.is_available() else "cpu")
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
    
    def clean_prompt(prompt: str) -> str:
        prompt = prompt.replace("wired", "wireless")
        prompt = prompt.replace("cables", "no visible cables")
        prompt = prompt.replace("clutter", "clean and organized")
        prompt = prompt.replace("noisy background", "neutral background")
        # ì“°ë ˆê¸° ì œê±°
        trash_keywords = ["trash", "mess", "noodles", "instant ramen", "wires", "tangled"]
        for word in trash_keywords:
            if word in prompt:
                prompt = prompt.replace(word, "")
        return prompt.strip()
    
    def generate_caption(self, image_path: str) -> str:
        # Blip2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±
        # image_path: S3ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ ê²½ë¡œ
        # s3 ì¸í’‹ ë°›ì•„ì„œ ì²˜ë¦¬ 
        image = Image.open(image_path).convert("RGB")
        inputs = self.processor(image, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")
        generated_ids = self.model.generate(**inputs, max_new_tokens=70)
        caption = self.processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)
        
        
        # GPT-4o í”„ë¡¬í”„íŠ¸ ìƒì„±
        response = self.client.chat.completions.create(
            model="gpt-4o",
            # messages=[
            #     {"role": "system", "content": "You are a creative prompt engineer for image generation."},
            #     {"role": "user", "content": f"Make this into a vivid prompt for image generation: {caption}"}
            # ],
            # temperature=0.8, # 1ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ì°½ì˜ì„±ì´ ë†’ì•„ì§.
            messages = [
            {
                "role": "system",
                "content": (
                    "You are an expert prompt engineer for text-to-image models like Stable Diffusion XL. "
                    "Your job is to take short captions and rewrite them into detailed, vivid, and highly descriptive prompts "
                    "suitable for realistic image generation. Use natural, photographic descriptions and focus on visual details, "
                    "lighting, atmosphere, and realistic object arrangements. Keep the total prompt under 70 tokens."
                )
            },
            {
                "role": "user",
                "content": f"Caption: {caption}\nPlease rewrite this into a vivid image generation prompt."
            }
            ],
            temperature=0.6,
            max_tokens=70
        )

        # âœ… ê°ì²´ ì†ì„± ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼
        generated_prompt = response.choices[0].message.content
        # print(f"ğŸ¨ [GPT-4o Prompt]: {generated_prompt}")
        
        # ë¶ˆí•„ìš”í•œ í”„ë¡¬í”„íŠ¸ ì œê±°
        generated_prompt = self.clean_prompt(generated_prompt)
        
        return generated_prompt